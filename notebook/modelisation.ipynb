{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, RidgeClassifier, RidgeClassifierCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, roc_auc_score\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler, CondensedNearestNeighbour\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_Location</th>\n",
       "      <th>id_Date</th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Climate</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Season</th>\n",
       "      <th>WindGustDir_cos</th>\n",
       "      <th>WindGustDir_sin</th>\n",
       "      <th>WindDir9am_cos</th>\n",
       "      <th>WindDir9am_sin</th>\n",
       "      <th>WindDir3pm_cos</th>\n",
       "      <th>WindDir3pm_sin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2008-07-01</td>\n",
       "      <td>2008-07-01</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>8.8</td>\n",
       "      <td>15.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Temperate</td>\n",
       "      <td>2008</td>\n",
       "      <td>July</td>\n",
       "      <td>Winter</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2008-07-02</td>\n",
       "      <td>2008-07-02</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>12.7</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Temperate</td>\n",
       "      <td>2008</td>\n",
       "      <td>July</td>\n",
       "      <td>Winter</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.923880</td>\n",
       "      <td>-0.382683</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2008-07-03</td>\n",
       "      <td>2008-07-03</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>6.2</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Temperate</td>\n",
       "      <td>2008</td>\n",
       "      <td>July</td>\n",
       "      <td>Winter</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.923880</td>\n",
       "      <td>0.382683</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2008-07-04</td>\n",
       "      <td>2008-07-04</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>5.3</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Temperate</td>\n",
       "      <td>2008</td>\n",
       "      <td>July</td>\n",
       "      <td>Winter</td>\n",
       "      <td>9.238795e-01</td>\n",
       "      <td>0.382683</td>\n",
       "      <td>0.923880</td>\n",
       "      <td>0.382683</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2008-07-07</td>\n",
       "      <td>2008-07-07</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>7.6</td>\n",
       "      <td>11.2</td>\n",
       "      <td>16.2</td>\n",
       "      <td>46.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Temperate</td>\n",
       "      <td>2008</td>\n",
       "      <td>July</td>\n",
       "      <td>Winter</td>\n",
       "      <td>-3.826834e-01</td>\n",
       "      <td>-0.923880</td>\n",
       "      <td>0.382683</td>\n",
       "      <td>-0.923880</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_Location     id_Date        Date  Location  MinTemp  MaxTemp  Rainfall  \\\n",
       "0    Adelaide  2008-07-01  2008-07-01  Adelaide      8.8     15.7       5.0   \n",
       "1    Adelaide  2008-07-02  2008-07-02  Adelaide     12.7     15.8       0.8   \n",
       "2    Adelaide  2008-07-03  2008-07-03  Adelaide      6.2     15.1       0.0   \n",
       "3    Adelaide  2008-07-04  2008-07-04  Adelaide      5.3     15.9       0.0   \n",
       "4    Adelaide  2008-07-07  2008-07-07  Adelaide      7.6     11.2      16.2   \n",
       "\n",
       "   WindGustSpeed  WindSpeed9am  WindSpeed3pm  ...    Climate  Year  Month  \\\n",
       "0           48.0          13.0          15.0  ...  Temperate  2008   July   \n",
       "1           35.0          13.0          15.0  ...  Temperate  2008   July   \n",
       "2           20.0           2.0          11.0  ...  Temperate  2008   July   \n",
       "3           30.0           6.0          13.0  ...  Temperate  2008   July   \n",
       "4           46.0          17.0          13.0  ...  Temperate  2008   July   \n",
       "\n",
       "   Season  WindGustDir_cos  WindGustDir_sin  WindDir9am_cos  WindDir9am_sin  \\\n",
       "0  Winter     7.071068e-01        -0.707107       -0.707107       -0.707107   \n",
       "1  Winter    -7.071068e-01        -0.707107       -0.923880       -0.382683   \n",
       "2  Winter    -1.836970e-16        -1.000000        0.923880        0.382683   \n",
       "3  Winter     9.238795e-01         0.382683        0.923880        0.382683   \n",
       "4  Winter    -3.826834e-01        -0.923880        0.382683       -0.923880   \n",
       "\n",
       "  WindDir3pm_cos  WindDir3pm_sin  \n",
       "0  -1.836970e-16       -1.000000  \n",
       "1  -7.071068e-01       -0.707107  \n",
       "2  -7.071068e-01       -0.707107  \n",
       "3   7.071068e-01        0.707107  \n",
       "4  -7.071068e-01       -0.707107  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data_saved/data_mat.csv')\n",
    "df_gps = pd.read_csv('../data/cities_coordinates_gps.csv', index_col = 0).T\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135600 entries, 0 to 135599\n",
      "Data columns (total 28 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   id_Location      135600 non-null  object \n",
      " 1   id_Date          135600 non-null  object \n",
      " 2   Date             135600 non-null  object \n",
      " 3   Location         135600 non-null  object \n",
      " 4   MinTemp          135600 non-null  float64\n",
      " 5   MaxTemp          135600 non-null  float64\n",
      " 6   Rainfall         135600 non-null  float64\n",
      " 7   WindGustSpeed    135600 non-null  float64\n",
      " 8   WindSpeed9am     135600 non-null  float64\n",
      " 9   WindSpeed3pm     135600 non-null  float64\n",
      " 10  Humidity9am      135600 non-null  float64\n",
      " 11  Humidity3pm      135600 non-null  float64\n",
      " 12  Pressure9am      135600 non-null  float64\n",
      " 13  Pressure3pm      135600 non-null  float64\n",
      " 14  Temp9am          135600 non-null  float64\n",
      " 15  Temp3pm          135600 non-null  float64\n",
      " 16  RainToday        135600 non-null  float64\n",
      " 17  RainTomorrow     135600 non-null  float64\n",
      " 18  Climate          135600 non-null  object \n",
      " 19  Year             135600 non-null  int64  \n",
      " 20  Month            135600 non-null  object \n",
      " 21  Season           135600 non-null  object \n",
      " 22  WindGustDir_cos  135600 non-null  float64\n",
      " 23  WindGustDir_sin  135600 non-null  float64\n",
      " 24  WindDir9am_cos   135600 non-null  float64\n",
      " 25  WindDir9am_sin   135600 non-null  float64\n",
      " 26  WindDir3pm_cos   135600 non-null  float64\n",
      " 27  WindDir3pm_sin   135600 non-null  float64\n",
      "dtypes: float64(20), int64(1), object(7)\n",
      "memory usage: 29.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encodage des locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gps_lat'] = df['Location'].map(lambda x : df_gps.loc[x, 'lat'])\n",
    "df['gps_lon'] = df['Location'].map(lambda x : df_gps.loc[x, 'long'])\n",
    "\n",
    "df['sin_lat'] = df['gps_lat'].apply(lambda x : np.sin(np.radians(x)))\n",
    "df['cos_lat'] = df['gps_lat'].apply(lambda x : np.cos(np.radians(x)))\n",
    "\n",
    "df['sin_lon'] = df['gps_lon'].apply(lambda x : np.round(np.sin(np.radians(x)), 6))\n",
    "df['cos_lon'] = df['gps_lon'].apply(lambda x : np.round(np.cos(np.radians(x)), 6))\n",
    "\n",
    "df = df.drop(columns = ['Location', 'id_Location', 'gps_lat', 'gps_lon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encodage Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_mois = {\n",
    "    'January': 1,\n",
    "    'February': 2,\n",
    "    'March': 3,\n",
    "    'April': 4,\n",
    "    'May': 5,\n",
    "    'June': 6,\n",
    "    'July': 7,\n",
    "    'August': 8,\n",
    "    'September': 9,\n",
    "    'October': 10,\n",
    "    'November': 11,\n",
    "    'December': 12\n",
    "}\n",
    "\n",
    "df['Month'] = df['Month'].map(dict_mois)\n",
    "\n",
    "df['sin_month'] = df['Month'].apply(lambda x : np.sin((2 * np.pi) * (( x - 1 ) / 12)))\n",
    "df['cos_month'] = df['Month'].apply(lambda x : np.cos((2 * np.pi) * (( x - 1 ) / 12)))\n",
    "\n",
    "\n",
    "df = df.drop(columns = 'Month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encodage season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Winter', 'Spring', 'Summer', 'Autumn'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Season'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375713/907855078.py:10: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  df['sin_season'] = df['Season'].apply(lambda x : round(np.sin((2 * np.pi) * (x / 4))), 1)\n",
      "/tmp/ipykernel_375713/907855078.py:11: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  df['cos_season'] = df['Season'].apply(lambda x : round(np.cos((2 * np.pi) * ( x / 4))), 1)\n"
     ]
    }
   ],
   "source": [
    "dict_season = {\n",
    "    'Spring' : 0,\n",
    "    'Summer' : 1,\n",
    "    'Autumn' : 2,\n",
    "    'Winter' : 3\n",
    "}\n",
    "\n",
    "df['Season'] = df['Season'].map(dict_season)\n",
    "\n",
    "df['sin_season'] = df['Season'].apply(lambda x : round(np.sin((2 * np.pi) * (x / 4))), 1)\n",
    "df['cos_season'] = df['Season'].apply(lambda x : round(np.cos((2 * np.pi) * ( x / 4))), 1)\n",
    "\n",
    "df = df.drop(columns = 'Season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encodage Climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output = False)\n",
    "\n",
    "climate_transform = ohe.fit_transform(df[['Climate']])\n",
    "df_climate_ohe = pd.DataFrame(climate_transform, columns = ohe.get_feature_names_out())\n",
    "\n",
    "df = pd.concat([df, df_climate_ohe], axis = 1)\n",
    "\n",
    "df = df.drop(columns = 'Climate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_Date', 'Date', 'MinTemp', 'MaxTemp', 'Rainfall', 'WindGustSpeed',\n",
       "       'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm',\n",
       "       'Pressure9am', 'Pressure3pm', 'Temp9am', 'Temp3pm', 'RainToday',\n",
       "       'RainTomorrow', 'Year', 'WindGustDir_cos', 'WindGustDir_sin',\n",
       "       'WindDir9am_cos', 'WindDir9am_sin', 'WindDir3pm_cos', 'WindDir3pm_sin',\n",
       "       'sin_lat', 'cos_lat', 'sin_lon', 'cos_lon', 'sin_month', 'cos_month',\n",
       "       'sin_season', 'cos_season', 'Climate_Desert', 'Climate_Grassland',\n",
       "       'Climate_Subtropical', 'Climate_Temperate', 'Climate_Tropical'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_Date</th>\n",
       "      <th>Date</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>cos_lon</th>\n",
       "      <th>sin_month</th>\n",
       "      <th>cos_month</th>\n",
       "      <th>sin_season</th>\n",
       "      <th>cos_season</th>\n",
       "      <th>Climate_Desert</th>\n",
       "      <th>Climate_Grassland</th>\n",
       "      <th>Climate_Subtropical</th>\n",
       "      <th>Climate_Temperate</th>\n",
       "      <th>Climate_Tropical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-07-01</td>\n",
       "      <td>2008-07-01</td>\n",
       "      <td>8.8</td>\n",
       "      <td>15.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.750119</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-07-02</td>\n",
       "      <td>2008-07-02</td>\n",
       "      <td>12.7</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.750119</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-07-03</td>\n",
       "      <td>2008-07-03</td>\n",
       "      <td>6.2</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.750119</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-07-04</td>\n",
       "      <td>2008-07-04</td>\n",
       "      <td>5.3</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.750119</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-07-07</td>\n",
       "      <td>2008-07-07</td>\n",
       "      <td>7.6</td>\n",
       "      <td>11.2</td>\n",
       "      <td>16.2</td>\n",
       "      <td>46.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.750119</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_Date        Date  MinTemp  MaxTemp  Rainfall  WindGustSpeed  \\\n",
       "0  2008-07-01  2008-07-01      8.8     15.7       5.0           48.0   \n",
       "1  2008-07-02  2008-07-02     12.7     15.8       0.8           35.0   \n",
       "2  2008-07-03  2008-07-03      6.2     15.1       0.0           20.0   \n",
       "3  2008-07-04  2008-07-04      5.3     15.9       0.0           30.0   \n",
       "4  2008-07-07  2008-07-07      7.6     11.2      16.2           46.0   \n",
       "\n",
       "   WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...   cos_lon  \\\n",
       "0          13.0          15.0         92.0         67.0  ... -0.750119   \n",
       "1          13.0          15.0         75.0         52.0  ... -0.750119   \n",
       "2           2.0          11.0         81.0         56.0  ... -0.750119   \n",
       "3           6.0          13.0         71.0         46.0  ... -0.750119   \n",
       "4          17.0          13.0         83.0         88.0  ... -0.750119   \n",
       "\n",
       "      sin_month  cos_month  sin_season  cos_season  Climate_Desert  \\\n",
       "0  1.224647e-16       -1.0          -1           0             0.0   \n",
       "1  1.224647e-16       -1.0          -1           0             0.0   \n",
       "2  1.224647e-16       -1.0          -1           0             0.0   \n",
       "3  1.224647e-16       -1.0          -1           0             0.0   \n",
       "4  1.224647e-16       -1.0          -1           0             0.0   \n",
       "\n",
       "   Climate_Grassland  Climate_Subtropical  Climate_Temperate  Climate_Tropical  \n",
       "0                0.0                  0.0                1.0               0.0  \n",
       "1                0.0                  0.0                1.0               0.0  \n",
       "2                0.0                  0.0                1.0               0.0  \n",
       "3                0.0                  0.0                1.0               0.0  \n",
       "4                0.0                  0.0                1.0               0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['id_Date', 'Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - modelisation simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = 'RainTomorrow')\n",
    "y = df['RainTomorrow']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a - tres simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.8478982300884956\n",
      "\n",
      "f1 score :  0.5855520948457752\n",
      "roc-auc score :  0.7194746831985506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.95      0.91     21187\n",
      "         1.0       0.72      0.49      0.59      5933\n",
      "\n",
      "    accuracy                           0.85     27120\n",
      "   macro avg       0.80      0.72      0.75     27120\n",
      "weighted avg       0.84      0.85      0.84     27120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathieu/.pyenv/versions/3.10.6/envs/meteo-venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b - tres simple avec stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.8476401179941003\n",
      "\n",
      "f1 score :  0.5931469082315872\n",
      "roc-auc score :  0.7238972332522922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.95      0.91     21119\n",
      "         1.0       0.72      0.50      0.59      6001\n",
      "\n",
      "    accuracy                           0.85     27120\n",
      "   macro avg       0.80      0.72      0.75     27120\n",
      "weighted avg       0.84      0.85      0.84     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c - avec mise à l'echelle [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.846976401179941\n",
      "\n",
      "f1 score :  0.5917765099350777\n",
      "roc-auc score :  0.7232325003774212\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.95      0.91     21119\n",
      "         1.0       0.72      0.50      0.59      6001\n",
      "\n",
      "    accuracy                           0.85     27120\n",
      "   macro avg       0.80      0.72      0.75     27120\n",
      "weighted avg       0.84      0.85      0.84     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range = (-1, 1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d - avec standardscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.8474926253687316\n",
      "\n",
      "f1 score :  0.5929935052155088\n",
      "roc-auc score :  0.723862175881967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.95      0.91     21119\n",
      "         1.0       0.72      0.50      0.59      6001\n",
      "\n",
      "    accuracy                           0.85     27120\n",
      "   macro avg       0.80      0.72      0.75     27120\n",
      "weighted avg       0.84      0.85      0.84     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter = 500)\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.8471976401179941\n",
      "\n",
      "f1 score :  0.5921259842519685\n",
      "roc-auc score :  0.723374552557922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.95      0.91     21119\n",
      "         1.0       0.72      0.50      0.59      6001\n",
      "\n",
      "    accuracy                           0.85     27120\n",
      "   macro avg       0.80      0.72      0.75     27120\n",
      "weighted avg       0.84      0.85      0.84     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter = 500)\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusion 1 : je continue avec un minmaxscaler [-1, 1], augmenter le nom d'iter ne sert à rien, je garde straify = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Re *Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a - undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.7934734513274336\n",
      "\n",
      "f1 score :  0.6235634115195914\n",
      "roc-auc score :  0.7861590479904785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.80      0.86     21119\n",
      "         1.0       0.52      0.77      0.62      6001\n",
      "\n",
      "    accuracy                           0.79     27120\n",
      "   macro avg       0.72      0.79      0.74     27120\n",
      "weighted avg       0.84      0.79      0.81     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "sample = RandomUnderSampler(random_state = 42)\n",
    "\n",
    "X_train_s, y_train_s = sample.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_s)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter = 500)\n",
    "\n",
    "model.fit(X_train_scaled, y_train_s)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b - oversampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.7923672566371681\n",
      "\n",
      "f1 score :  0.621496269409155\n",
      "roc-auc score :  0.784494481754501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.80      0.86     21119\n",
      "         1.0       0.52      0.77      0.62      6001\n",
      "\n",
      "    accuracy                           0.79     27120\n",
      "   macro avg       0.72      0.78      0.74     27120\n",
      "weighted avg       0.84      0.79      0.80     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "sample = SMOTE(random_state = 42)\n",
    "\n",
    "X_train_s, y_train_s = sample.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_s)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter = 500)\n",
    "\n",
    "model.fit(X_train_scaled, y_train_s)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusion : les stratégie d'undersampling est la plus efficace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - test différence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.7932890855457227\n",
      "\n",
      "f1 score :  0.6232020432853879\n",
      "roc-auc score :  0.7858617389233682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.80      0.86     21119\n",
      "         1.0       0.52      0.77      0.62      6001\n",
      "\n",
      "    accuracy                           0.79     27120\n",
      "   macro avg       0.72      0.79      0.74     27120\n",
      "weighted avg       0.84      0.79      0.81     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "sample = RandomUnderSampler(random_state = 42)\n",
    "\n",
    "X_train_s, y_train_s = sample.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_s)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegressionCV(max_iter = 500)\n",
    "\n",
    "model.fit(X_train_scaled, y_train_s)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.7936578171091445\n",
      "\n",
      "f1 score :  0.6204557786218122\n",
      "roc-auc score :  0.7824005593903297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.80      0.86     21119\n",
      "         1.0       0.52      0.76      0.62      6001\n",
      "\n",
      "    accuracy                           0.79     27120\n",
      "   macro avg       0.72      0.78      0.74     27120\n",
      "weighted avg       0.83      0.79      0.81     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "sample = RandomUnderSampler(random_state = 42)\n",
    "\n",
    "X_train_s, y_train_s = sample.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_s)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = SGDClassifier(max_iter = 2000, n_jobs = -1)\n",
    "\n",
    "model.fit(X_train_scaled, y_train_s)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.8165929203539823\n",
      "\n",
      "f1 score :  0.6620923913043478\n",
      "roc-auc score :  0.8149602163548684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.82      0.87     21119\n",
      "         1.0       0.56      0.81      0.66      6001\n",
      "\n",
      "    accuracy                           0.82     27120\n",
      "   macro avg       0.75      0.81      0.77     27120\n",
      "weighted avg       0.85      0.82      0.83     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "sample = RandomUnderSampler(random_state = 42)\n",
    "\n",
    "X_train_s, y_train_s = sample.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_s)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = RandomForestClassifier(n_jobs = -1)\n",
    "\n",
    "model.fit(X_train_scaled, y_train_s)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.7231932153392331\n",
      "\n",
      "f1 score :  0.5382864874838551\n",
      "roc-auc score :  0.7253474113990457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.72      0.80     21119\n",
      "         1.0       0.43      0.73      0.54      6001\n",
      "\n",
      "    accuracy                           0.72     27120\n",
      "   macro avg       0.67      0.73      0.67     27120\n",
      "weighted avg       0.80      0.72      0.74     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "sample = RandomUnderSampler(random_state = 42)\n",
    "\n",
    "X_train_s, y_train_s = sample.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_s)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "model.fit(X_train_scaled, y_train_s)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 500\n",
      "obj = -985.535335, rho = -0.493495\n",
      "nSV = 1000, nBSV = 1000\n",
      "Total nSV = 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathieu/.pyenv/versions/3.10.6/envs/meteo-venv/lib/python3.10/site-packages/sklearn/svm/_base.py:304: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.7803466076696165\n",
      "\n",
      "f1 score :  0.3735408560311284\n",
      "roc-auc score :  0.6069696080058125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.92      0.87     21119\n",
      "         1.0       0.51      0.30      0.37      6001\n",
      "\n",
      "    accuracy                           0.78     27120\n",
      "   macro avg       0.66      0.61      0.62     27120\n",
      "weighted avg       0.75      0.78      0.76     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "sample = RandomUnderSampler(random_state = 42)\n",
    "\n",
    "X_train_s, y_train_s = sample.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_s)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = SVC(verbose = 2, max_iter = 500)\n",
    "\n",
    "model.fit(X_train_scaled, y_train_s)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusion : on va partir sur un RandomForrestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - exploration des hyperparametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.8686209439528023\n",
      "\n",
      "f1 score :  0.6701231367465975\n",
      "roc-auc score :  0.773572473625089\n",
      "Confusion Matrix :\n",
      "[[19938  1181]\n",
      " [ 2382  3619]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_s, y_train_s = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_s)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators = 200,\n",
    "    max_features = 'sqrt',\n",
    "    criterion = 'entropy',\n",
    "    max_depth = 30,\n",
    "    bootstrap = False,\n",
    "    min_samples_split = 5,\n",
    "    min_samples_leaf = 2,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train_s)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print('Confusion Matrix :')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score accuracy :  0.8169616519174041\n",
      "\n",
      "f1 score :  0.6620370370370371\n",
      "roc-auc score :  0.8145408850722742\n",
      "[[17294  3825]\n",
      " [ 1139  4862]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.82      0.87     21119\n",
      "         1.0       0.56      0.81      0.66      6001\n",
      "\n",
      "    accuracy                           0.82     27120\n",
      "   macro avg       0.75      0.81      0.77     27120\n",
      "weighted avg       0.85      0.82      0.83     27120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "sample = RandomUnderSampler(random_state = 42)\n",
    "\n",
    "X_train_s, y_train_s = sample.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_s)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_jobs = -1)\n",
    "\n",
    "model.fit(X_train_scaled, y_train_s)\n",
    "\n",
    "print('score accuracy : ', model.score(X_test_scaled, y_test), end = '\\n\\n')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres : {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Meilleur score F1 : 0.811748518802989\n",
      "f1 score :  0.6663512234689739\n",
      "roc-auc score :  0.8191999488318625\n",
      "[[17255  3864]\n",
      " [ 1072  4929]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.82      0.87     21119\n",
      "         1.0       0.56      0.82      0.67      6001\n",
      "\n",
      "    accuracy                           0.82     27120\n",
      "   macro avg       0.75      0.82      0.77     27120\n",
      "weighted avg       0.86      0.82      0.83     27120\n",
      "\n",
      "Score accuracy :  0.8179941002949852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "sample = RandomUnderSampler(random_state=42)\n",
    "X_train_s, y_train_s = sample.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_train_scaled = scaler.fit_transform(X_train_s)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200],\n",
    "    'max_features': ['sqrt'],\n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [30],\n",
    "    'bootstrap': [False],\n",
    "    'min_samples_split': [5],\n",
    "    'min_samples_leaf': [2],\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    verbose=0,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train_s)\n",
    "\n",
    "print(f\"Meilleurs paramètres : {grid_search.best_params_}\")\n",
    "print(f\"Meilleur score F1 : {grid_search.best_score_}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('Score accuracy : ', best_model.score(X_test_scaled, y_test), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres : {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Meilleur score F1 : 0.812449602854503\n",
      "f1 score :  0.667882225823879\n",
      "roc-auc score :  0.8205804107068381\n",
      "[[17257  3862]\n",
      " [ 1056  4945]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.82      0.88     21119\n",
      "         1.0       0.56      0.82      0.67      6001\n",
      "\n",
      "    accuracy                           0.82     27120\n",
      "   macro avg       0.75      0.82      0.77     27120\n",
      "weighted avg       0.86      0.82      0.83     27120\n",
      "\n",
      "Score accuracy :  0.8186578171091445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "sample = RandomUnderSampler(random_state=42)\n",
    "X_train_s, y_train_s = sample.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_train_scaled = scaler.fit_transform(X_train_s)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200],\n",
    "    'max_features': ['sqrt'],\n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [30],\n",
    "    'bootstrap': [False],\n",
    "    'min_samples_split': [5],\n",
    "    'min_samples_leaf': [2],\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    verbose=0,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train_s)\n",
    "\n",
    "print(f\"Meilleurs paramètres : {grid_search.best_params_}\")\n",
    "print(f\"Meilleur score F1 : {grid_search.best_score_}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('Score accuracy : ', best_model.score(X_test_scaled, y_test), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres : {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt'}\n",
      "Meilleur score F1 : 0.8091781696461833\n",
      "f1 score :  0.6595079516107109\n",
      "roc-auc score :  0.8128553775216797\n",
      "[[17258  3861]\n",
      " [ 1149  4852]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.82      0.87     21119\n",
      "         1.0       0.56      0.81      0.66      6001\n",
      "\n",
      "    accuracy                           0.82     27120\n",
      "   macro avg       0.75      0.81      0.77     27120\n",
      "weighted avg       0.85      0.82      0.83     27120\n",
      "\n",
      "Score accuracy :  0.8152654867256637\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "sample = RandomUnderSampler(random_state=42)\n",
    "X_train_s, y_train_s = sample.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_train_scaled = scaler.fit_transform(X_train_s)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "param_grid = {\n",
    "    # 'n_estimators': [100, 200],\n",
    "    'max_features': ['sqrt'],\n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    # 'min_samples_split': [2, 5, 10],\n",
    "    # 'min_samples_leaf': [1, 2, 4],\n",
    "    # 'bootstrap': [True, False],\n",
    "    # 'warm_start': [True, False]\n",
    "}\n",
    "\n",
    "model = ExtraTreesClassifier(\n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    verbose=0,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train_s)\n",
    "\n",
    "print(f\"Meilleurs paramètres : {grid_search.best_params_}\")\n",
    "print(f\"Meilleur score F1 : {grid_search.best_score_}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "print('f1 score : ', f1_score(y_test, y_pred))\n",
    "print('roc-auc score : ', roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('Score accuracy : ', best_model.score(X_test_scaled, y_test), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meteo-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
